{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Data entered by humans or captured from devices are generally (though not always) not in ideal form for machine consumption. Data may not be in appropriate format (not properly encoded), have ranges that are too large (not scaled), be noisy or contain outliers, missing data, may be highly imbalanced, or any number of issues. To build a model, we must first prepare the data, converting it from the messy raw form collected from the system(s) of interest to a format amenable to machine consumption. Here, we will explore the concepts of scaling, imputations, synthetic minority oversampling (SMOTE) and random undersampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, StandardScaler, MinMaxScaler\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enable_iterative_imputer\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/sklearn/__init__.py:83\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     80\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     81\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     )\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     86\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m     ]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/sklearn/utils/__init__.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/sklearn/utils/validation.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isfinite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FiniteStatus, cy_isfinite\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _object_dtype_isnan\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/sklearn/utils/_array_api.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_array_api_dispatch\u001b[39m(array_api_dispatch):\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that array_api_compat is installed and NumPy version is compatible.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    array_api_compat follows NEP29, which has a higher minimum NumPy version than\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    scikit-learn.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/sklearn/utils/fixes.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreadpoolctl\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/scipy/stats/__init__.py:608\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m \n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    607\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 608\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/scipy/stats/_stats_py.py:46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributions\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _mstats_basic \u001b[38;5;28;01mas\u001b[39;00m mstats_basic\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_mstats_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_find_repeats, linregress, theilslopes,\n\u001b[1;32m     49\u001b[0m                                    siegelslopes)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/scipy/stats/distributions.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Author:  Travis Oliphant  2002-2011 with contributions from\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#          SciPy Developers 2004-2011\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#       instead of `git blame -Lxxx,+x`.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_distn_infrastructure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (rv_discrete, rv_continuous, rv_frozen)  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _continuous_distns\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _discrete_distns\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py:23\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m comb, entr\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# for root finding for continuous distribution ppf, and maximum likelihood\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# estimation\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m integrate\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/scipy/__init__.py:189\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[0;32m--> 189\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_importlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscipy.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/scipy/optimize/__init__.py:422\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nnls\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nnls\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_basinhopping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m basinhopping\n\u001b[0;32m--> 422\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_linprog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linprog, linprog_verbose_callback\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lsap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linear_sum_assignment\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_differentialevolution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m differential_evolution\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/scipy/optimize/_linprog.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_linprog_highs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _linprog_highs\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_linprog_ip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _linprog_ip\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_linprog_simplex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _linprog_simplex\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_linprog_rs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _linprog_rs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310_datascience/lib/python3.10/site-packages/scipy/optimize/_linprog_ip.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinAlgError\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptimizeWarning, OptimizeResult, _check_unknown_options\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_linprog_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _postsolve\n\u001b[1;32m     28\u001b[0m has_umfpack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     29\u001b[0m has_cholmod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LogisticRegression, BayesianRidge\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RootDir = '/Users/ggray15/src/python/repos/jhach_cpdsam_symposium_workshop'\n",
    "os.chdir(RootDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook contains some common functions that are reused. They are included in one source for clarity.\n",
    "%run \"./notebooks/common/function_library.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "Data is often missing in real world data. As a result, there are numerous approaches and techniques developed to handle missing data in real world scenarios. These vary by situation. Data can be missing completely at random, missing at random, or not missing at random. All three rely on assumptions made about the data. Missinge completely at random (MCAR) means that missing data is not dependent upon other variables. An example of this would be a clinician forgets to enter a value some percentage of the time, or forgets to attach leads from a vital sign. Missing at random refers to the instance where missing data can be explained by other data distributions. For example, missing blood pressure explained by age/weight. A clinician may decide that taking blood pressure is not necessary for patients depending on their age/weight. \n",
    "\n",
    "For further explanation see https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4121561/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>insurance</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>total_rx</th>\n",
       "      <th>total_dx</th>\n",
       "      <th>los</th>\n",
       "      <th>abnormal_lab_fraction</th>\n",
       "      <th>micro_organism</th>\n",
       "      <th>icd9_code_V053</th>\n",
       "      <th>icd9_code_V290</th>\n",
       "      <th>icd9_code_7742</th>\n",
       "      <th>icd9_code_769</th>\n",
       "      <th>readmit_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>Private</td>\n",
       "      <td>ASIAN</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>Private</td>\n",
       "      <td>ASIAN</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>Private</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>Private</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7391</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>Private</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0755</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8095</th>\n",
       "      <td>M</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>Private</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2158</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8096</th>\n",
       "      <td>M</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>Private</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3103</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8097</th>\n",
       "      <td>F</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>Private</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1894</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8098</th>\n",
       "      <td>F</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>Private</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>23</td>\n",
       "      <td>138.9928</td>\n",
       "      <td>0.367747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8099</th>\n",
       "      <td>M</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>Private</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NEWBORN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>12.5199</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender admission_type insurance ethnicity diagnosis  total_rx  total_dx  \\\n",
       "0         M        NEWBORN   Private     ASIAN   NEWBORN       2.0         3   \n",
       "1         M        NEWBORN   Private     ASIAN   NEWBORN       0.0         3   \n",
       "2         F        NEWBORN   Private     WHITE   NEWBORN       0.0         3   \n",
       "3         F        NEWBORN   Private     WHITE   NEWBORN       0.0         3   \n",
       "4         M        NEWBORN   Private     WHITE   NEWBORN       2.0         6   \n",
       "...     ...            ...       ...       ...       ...       ...       ...   \n",
       "8095      M        NEWBORN   Private     WHITE   NEWBORN       0.0         1   \n",
       "8096      M        NEWBORN   Private     WHITE   NEWBORN       2.0         4   \n",
       "8097      F        NEWBORN   Private     WHITE   NEWBORN       0.0         3   \n",
       "8098      F        NEWBORN   Private     WHITE   NEWBORN      43.0        23   \n",
       "8099      M        NEWBORN   Private     WHITE   NEWBORN       5.0         7   \n",
       "\n",
       "           los  abnormal_lab_fraction  micro_organism  icd9_code_V053  \\\n",
       "0       0.0918               0.340426             0.0               1   \n",
       "1       0.0844               0.263158             0.0               1   \n",
       "2       0.2677               0.357143             0.0               1   \n",
       "3       0.7391               0.357143             0.0               1   \n",
       "4       1.0755               0.400000             0.0               1   \n",
       "...        ...                    ...             ...             ...   \n",
       "8095    0.2158               0.400000             0.0               0   \n",
       "8096    0.3103               0.277778             0.0               0   \n",
       "8097    0.1894               0.250000             0.0               1   \n",
       "8098  138.9928               0.367747             1.0               1   \n",
       "8099   12.5199               0.342105             0.0               1   \n",
       "\n",
       "      icd9_code_V290  icd9_code_7742  icd9_code_769  readmit_flag  \n",
       "0                  1               0              0             0  \n",
       "1                  1               0              0             0  \n",
       "2                  1               0              0             1  \n",
       "3                  1               0              0             0  \n",
       "4                  1               0              0             0  \n",
       "...              ...             ...            ...           ...  \n",
       "8095               0               0              0             0  \n",
       "8096               0               0              0             0  \n",
       "8097               1               0              0             0  \n",
       "8098               1               1              1             0  \n",
       "8099               1               0              0             0  \n",
       "\n",
       "[8100 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data using pandas\n",
    "input_df = pd.read_csv('data/tabula_data.csv')\n",
    "input_df['total_rx'] = input_df['total_rx'].fillna(0)\n",
    "input_df['abnormal_lab_fraction'] = input_df['abnormal_lab_fraction'].fillna(0)\n",
    "input_df['micro_organism'] = input_df['micro_organism'].fillna(2)\n",
    "input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test/Holdout Set\n",
    "\n",
    "The purpose of building a model is to use a model in real-life (i.e. deploy it). We cannot judge performance based solely on the data used to build (train) our model, but need to test it on data that the model has not been exposed to. The ability for a model to perform well on data it has not seen is called generalizability. To test this, we can split the data into a training and test (sometimes called the holdout) sets. Thus, a model is built using the train dataset and final evaluation occurs on the test/holdout set. To prevent a phenomenon known as data leakage, it is imperative that we remove the data prior to performing any data preparation steps. Here, we use the built in train_test_split function in scikit-learn (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Because of the class imbalance, we stratify the train/test split by the target feature to assure that we have equal fractions for both datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(input_df,test_size=0.3,random_state=42, stratify=input_df['readmit_flag'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dict = {\n",
    "    'readmit_flag':'int',\n",
    "    'total_rx_minmax':'int', \n",
    "    'total_dx_minmax':'int', \n",
    "    'los_scaled':'float', \n",
    "    'abnormal_lab_fraction':'float',\n",
    "    'micro_organism':'int', \n",
    "    'icd9_code_V053':'int', \n",
    "    'icd9_code_V290':'int', \n",
    "    'icd9_code_7742':'int',\n",
    "    'icd9_code_769':'int', \n",
    "    'admission_type_encode':'int',\n",
    "    'insurance_encode':'int', \n",
    "    'ethnicity_encode':'int', \n",
    "    'diagnosis_encode':'int'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Encoding\n",
    "\n",
    "Now we need to convert data to a machine readable format. We have four kinds of transformations, 1) LabelEncoder, 2) MinMaxScaler, 3) StandardScaler, 4) StrBinarizer.\n",
    "\n",
    "#### Label Encoder\n",
    "\n",
    "Maps categorical data to integer values. This is useful when the data is categorical, but not ordered (ordinal). As an example, large, medium, and small are ordinal, in that we know large > medium > small, however the magnitude of difference is not known. For ordinal data, the OrdinalEncoder can be used. \n",
    "\n",
    "#### MinMaxScaler\n",
    "\n",
    "Normalizes the data to the range of [0, 1]. This is best used when the data is roughly uniform or the values are integers.\n",
    "\n",
    "#### StandardScaler\n",
    "\n",
    "Standardizes the data, centering the distribution to a mean of 0 and standard deviation of 1. This is best used when the data is roughly normal. \n",
    "\n",
    "#### StrBinarizer\n",
    "\n",
    "This is a custom build function, which binarizes strings (encodes them to either 0 or 1). Here, the target_label -> 1, while the remaining values are converted to 0. Binarizers are useful when one class of the data comprises roughly 50% of the samples, and the remaining classes contain several other samples. \n",
    "\n",
    "For more on preprocessing, see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = StrBinarize(input_df=train_df, target_col='admission_type', target_label='NEWBORN')\n",
    "train_df = StrBinarize(input_df=train_df, target_col='insurance', target_label='Private')\n",
    "train_df = StrBinarize(input_df=train_df, target_col='ethnicity', target_label='WHITE')\n",
    "train_df = StrBinarize(input_df=train_df, target_col='diagnosis', target_label='NEWBORN')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train_df['gender'])\n",
    "train_df['gender_encode'] = label_encoder.transform(train_df['gender'])\n",
    "\n",
    "mx_0 = MinMaxScaler()\n",
    "mx_0.fit(train_df['total_rx'].values.reshape(-1,1))\n",
    "train_df['total_rx_minmax'] = mx_0.transform(train_df['total_rx'].values.reshape(-1,1))\n",
    "\n",
    "mx_1 = MinMaxScaler()\n",
    "mx_1.fit(train_df['total_dx'].values.reshape(-1,1))\n",
    "train_df['total_dx_minmax'] = mx_1.transform(train_df['total_dx'].values.reshape(-1,1))\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(train_df['los'].values.reshape(-1,1))\n",
    "train_df['los_scaled'] = sc.transform(train_df['los'].values.reshape(-1,1))\n",
    "\n",
    "train_df = train_df[list(type_dict.keys())]\n",
    "train_df = train_df.astype(type_dict)\n",
    "train_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent data leakage, we fit the encoding models on the training data, and then transform training and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = StrBinarize(input_df=test_df, target_col='admission_type', target_label='NEWBORN')\n",
    "test_df = StrBinarize(input_df=test_df, target_col='insurance', target_label='Private')\n",
    "test_df = StrBinarize(input_df=test_df, target_col='ethnicity', target_label='WHITE')\n",
    "test_df = StrBinarize(input_df=test_df, target_col='diagnosis', target_label='NEWBORN')\n",
    "\n",
    "test_df['gender_encode'] = label_encoder.transform(test_df['gender'])\n",
    "test_df['total_rx_minmax'] = mx_0.transform(test_df['total_rx'].values.reshape(-1,1))\n",
    "test_df['total_dx_minmax'] = mx_1.transform(test_df['total_dx'].values.reshape(-1,1))\n",
    "test_df['los_scaled'] = sc.transform(test_df['los'].values.reshape(-1,1))\n",
    "\n",
    "test_df = test_df[list(type_dict.keys())]\n",
    "test_df = test_df.astype(type_dict)\n",
    "test_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readmit_flag             0\n",
       "total_rx_minmax          0\n",
       "total_dx_minmax          0\n",
       "los_scaled               5\n",
       "abnormal_lab_fraction    0\n",
       "micro_organism           0\n",
       "icd9_code_V053           0\n",
       "icd9_code_V290           0\n",
       "icd9_code_7742           0\n",
       "icd9_code_769            0\n",
       "admission_type_encode    0\n",
       "insurance_encode         0\n",
       "ethnicity_encode         0\n",
       "diagnosis_encode         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missingness in the training data.\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readmit_flag             0\n",
       "total_rx_minmax          0\n",
       "total_dx_minmax          0\n",
       "los_scaled               2\n",
       "abnormal_lab_fraction    0\n",
       "micro_organism           0\n",
       "icd9_code_V053           0\n",
       "icd9_code_V290           0\n",
       "icd9_code_7742           0\n",
       "icd9_code_769            0\n",
       "admission_type_encode    0\n",
       "insurance_encode         0\n",
       "ethnicity_encode         0\n",
       "diagnosis_encode         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missingness in the test data.\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_df.columns[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation\n",
    "\n",
    "We can \n",
    "\n",
    "For more see https://scikit-learn.org/stable/modules/impute.html#impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the training data\n",
    "data_imputer = DataImputer()\n",
    "data_imputer.set_state(\n",
    "    cat_estimator=LogisticRegression(),\n",
    "    num_estimator=BayesianRidge(),\n",
    "    input_df=train_df[train_features])\n",
    "\n",
    "data_imputer.map_features()\n",
    "data_imputer.impute_data()\n",
    "\n",
    "train_impute, _, _ = data_imputer.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now impute the test set with the saved models\n",
    "data_imputer.set_state(\n",
    "    cat_estimator=LogisticRegression(),\n",
    "    num_estimator=BayesianRidge(),\n",
    "    input_df=test_df[train_features])\n",
    "\n",
    "data_imputer.map_features()\n",
    "data_imputer.impute_data()\n",
    "\n",
    "\n",
    "test_impute, _, _ = data_imputer.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_impute.insert(0,'readmit_flag',train_df['readmit_flag'])\n",
    "test_impute.insert(0,'readmit_flag',test_df['readmit_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_impute.to_csv('data/train_impute.csv',index=False)\n",
    "#test_impute.to_csv('data/test_impute.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_impute.columns[1:]\n",
    "target_feature = 'readmit_flag'\n",
    "\n",
    "# Get X/y\n",
    "X_train = train_impute[train_features]\n",
    "y_train = train_impute[target_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(sampling_strategy=0.1)\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', oversample), ('u', undersample)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "X_train_smote, y_train_smote = pipeline.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_smote = X_train_smote\n",
    "train_smote.insert(0, 'readmit_flag', y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_smote.to_csv('data/train_smote.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readmit_flag</th>\n",
       "      <th>total_rx_minmax</th>\n",
       "      <th>total_dx_minmax</th>\n",
       "      <th>los_scaled</th>\n",
       "      <th>abnormal_lab_fraction</th>\n",
       "      <th>micro_organism</th>\n",
       "      <th>icd9_code_V053</th>\n",
       "      <th>icd9_code_V290</th>\n",
       "      <th>icd9_code_7742</th>\n",
       "      <th>icd9_code_769</th>\n",
       "      <th>admission_type_encode</th>\n",
       "      <th>insurance_encode</th>\n",
       "      <th>ethnicity_encode</th>\n",
       "      <th>diagnosis_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.476909</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.318430</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333524</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.475208</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.422001</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.469757</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.267649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.732351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.461164</td>\n",
       "      <td>0.332290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.459377</td>\n",
       "      <td>0.401940</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.447530</td>\n",
       "      <td>0.462437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.478648</td>\n",
       "      <td>0.442694</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1659 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      readmit_flag  total_rx_minmax  total_dx_minmax  los_scaled  \\\n",
       "3640             0              0.0              0.0   -0.476909   \n",
       "3232             0              0.0              0.0   -0.318430   \n",
       "1765             0              0.0              0.0   -0.333524   \n",
       "132              0              0.0              0.0   -0.475208   \n",
       "3915             0              0.0              0.0   -0.422001   \n",
       "...            ...              ...              ...         ...   \n",
       "6086             1              0.0              0.0   -0.469757   \n",
       "6087             1              0.0              0.0   -0.461164   \n",
       "6088             1              0.0              0.0   -0.459377   \n",
       "6089             1              0.0              0.0   -0.447530   \n",
       "6090             1              0.0              0.0   -0.478648   \n",
       "\n",
       "      abnormal_lab_fraction  micro_organism  icd9_code_V053  icd9_code_V290  \\\n",
       "3640               0.166667        0.000000             1.0        1.000000   \n",
       "3232               0.428571        2.000000             1.0        0.000000   \n",
       "1765               0.406780        0.000000             0.0        1.000000   \n",
       "132                0.303030        0.000000             1.0        0.000000   \n",
       "3915               0.321429        0.000000             1.0        0.000000   \n",
       "...                     ...             ...             ...             ...   \n",
       "6086               0.266667        1.267649             1.0        0.732351   \n",
       "6087               0.332290        0.000000             1.0        1.000000   \n",
       "6088               0.401940        2.000000             1.0        0.000000   \n",
       "6089               0.462437        0.000000             1.0        1.000000   \n",
       "6090               0.442694        2.000000             1.0        0.000000   \n",
       "\n",
       "      icd9_code_7742  icd9_code_769  admission_type_encode  insurance_encode  \\\n",
       "3640             0.0            0.0                    0.0               1.0   \n",
       "3232             0.0            0.0                    0.0               0.0   \n",
       "1765             0.0            0.0                    0.0               0.0   \n",
       "132              0.0            0.0                    0.0               0.0   \n",
       "3915             0.0            0.0                    0.0               0.0   \n",
       "...              ...            ...                    ...               ...   \n",
       "6086             0.0            0.0                    0.0               1.0   \n",
       "6087             0.0            0.0                    0.0               0.0   \n",
       "6088             0.0            0.0                    0.0               0.0   \n",
       "6089             0.0            0.0                    0.0               0.0   \n",
       "6090             0.0            0.0                    0.0               0.0   \n",
       "\n",
       "      ethnicity_encode  diagnosis_encode  \n",
       "3640               1.0               0.0  \n",
       "3232               0.0               0.0  \n",
       "1765               0.0               0.0  \n",
       "132                0.0               0.0  \n",
       "3915               0.0               0.0  \n",
       "...                ...               ...  \n",
       "6086               1.0               0.0  \n",
       "6087               0.0               0.0  \n",
       "6088               0.0               0.0  \n",
       "6089               0.0               0.0  \n",
       "6090               0.0               0.0  \n",
       "\n",
       "[1659 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
